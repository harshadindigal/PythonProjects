{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB Move Ratings Sentiment Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshadindigal/PythonProjects/blob/master/IMDB_Move_Ratings_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqE0XZGjTjcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP59zk-STmKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "imdb,info = tfds.load(\"imdb_reviews\", with_info = True, as_supervised = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Sa2XvhTpjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "train,test = imdb['train'],imdb['test']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ES805v3TsUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sequences = []\n",
        "training_labels = []\n",
        "testing_sequences = []\n",
        "testing_labels = []\n",
        "\n",
        "for s,l in train:\n",
        "  training_sequences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())  \n",
        "for s,l in test:\n",
        "    testing_sequences.append(str(s.numpy()))\n",
        "    testing_labels.append(l.numpy())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "671XWOSWTu1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dcab72b4-6717-4fca-b19e-4d845128fafa"
      },
      "source": [
        "print(training_sequences[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"Oh yeah! Jenna Jameson did it again! Yeah Baby! This movie rocks. It was one of the 1st movies i saw of her. And i have to say i feel in love with her, she was great in this move.<br /><br />Her performance was outstanding and what i liked the most was the scenery and the wardrobe it was amazing you can tell that they put a lot into the movie the girls cloth were amazing.<br /><br />I hope this comment helps and u can buy the movie, the storyline is awesome is very unique and i'm sure u are going to like it. Jenna amazed us once more and no wonder the movie won so many awards. Her make-up and wardrobe is very very sexy and the girls on girls scene is amazing. specially the one where she looks like an angel. It's a must see and i hope u share my interests\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db5nC6vPUufa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_-M6axPWao2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "#Hyperparameters for ease of use\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGd6I6M5Wi-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "oov_tok = \"<OOV>\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xp1qRu_VNI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size,oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(training_sequences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sequences)\n",
        "padded = pad_sequences(sequences, maxlen = max_length,truncating = trunc_type)\n",
        "\n",
        "\n",
        "testing_sequence = tokenizer.texts_to_sequences(testing_sequences)\n",
        "testing_padded = pad_sequences(testing_sequence, maxlen = max_length)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aag_r66ZkE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size,embedding_dim, input_length = max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6,activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model_2 = model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size,embedding_dim, input_length = max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(6,activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AFN4g0raf-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "b713fb1b-2a96-45d7-beb2-376623491ef2"
      },
      "source": [
        "model_1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_1.summary() \n",
        "num_epochs = 10\n",
        "model_1.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 6)                 102       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 160,109\n",
            "Trainable params: 160,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 4s 176us/sample - loss: 0.6066 - acc: 0.6989 - val_loss: 0.4941 - val_acc: 0.8368\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 4s 159us/sample - loss: 0.4211 - acc: 0.8523 - val_loss: 0.3947 - val_acc: 0.8546\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 4s 157us/sample - loss: 0.3276 - acc: 0.8878 - val_loss: 0.3670 - val_acc: 0.8542\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 4s 155us/sample - loss: 0.2717 - acc: 0.9086 - val_loss: 0.3632 - val_acc: 0.8523\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 4s 157us/sample - loss: 0.2343 - acc: 0.9209 - val_loss: 0.3770 - val_acc: 0.8474\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 4s 157us/sample - loss: 0.2070 - acc: 0.9329 - val_loss: 0.4003 - val_acc: 0.8433\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 4s 157us/sample - loss: 0.1843 - acc: 0.9428 - val_loss: 0.4256 - val_acc: 0.8383\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 4s 157us/sample - loss: 0.1664 - acc: 0.9490 - val_loss: 0.4556 - val_acc: 0.8330\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 4s 156us/sample - loss: 0.1506 - acc: 0.9558 - val_loss: 0.4887 - val_acc: 0.8281\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 4s 168us/sample - loss: 0.1379 - acc: 0.9606 - val_loss: 0.5433 - val_acc: 0.8242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f678c8518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLs6EqHWcRuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "a6d66f6c-bab7-4e4d-afac-836d92fb687e"
      },
      "source": [
        "model_2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_2.summary() \n",
        "num_epochs = 10\n",
        "model_2.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 6)                 102       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 160,109\n",
            "Trainable params: 160,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 4s 179us/sample - loss: 0.1288 - acc: 0.9632 - val_loss: 0.5866 - val_acc: 0.8219\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 4s 158us/sample - loss: 0.1156 - acc: 0.9691 - val_loss: 0.6238 - val_acc: 0.8203\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 4s 156us/sample - loss: 0.1066 - acc: 0.9729 - val_loss: 0.6948 - val_acc: 0.8190\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 4s 159us/sample - loss: 0.0974 - acc: 0.9767 - val_loss: 0.7062 - val_acc: 0.8140\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 4s 156us/sample - loss: 0.0893 - acc: 0.9796 - val_loss: 0.7859 - val_acc: 0.8152\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 4s 157us/sample - loss: 0.0830 - acc: 0.9816 - val_loss: 0.8118 - val_acc: 0.8098\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 4s 157us/sample - loss: 0.0772 - acc: 0.9832 - val_loss: 0.8742 - val_acc: 0.8107\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 4s 159us/sample - loss: 0.0722 - acc: 0.9852 - val_loss: 0.9224 - val_acc: 0.8103\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 4s 159us/sample - loss: 0.0687 - acc: 0.9858 - val_loss: 0.9535 - val_acc: 0.8082\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 4s 166us/sample - loss: 0.0650 - acc: 0.9872 - val_loss: 1.0349 - val_acc: 0.8084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f678ca2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xY4gDQligLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b37243d-5b2a-4107-d9d0-0afffe1d7163"
      },
      "source": [
        "e = model_1.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igamt2G3iznW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrbvMTtCjOWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "out_v = io.open('vecs.tsv','w',encoding = 'utf-8')\n",
        "out_m = io.open('meta.tsv','w',encoding = 'utf-8')\n",
        "\n",
        "for word_num in range(1,vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd6V5zoekdfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}